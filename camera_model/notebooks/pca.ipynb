{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.data import imread\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/var/local/pgladkov/camera_model/data'\n",
    "train_path = data_path + '/train'\n",
    "test_path = data_path + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2750, 2)\n"
     ]
    }
   ],
   "source": [
    "cameras = os.listdir(train_path)\n",
    "\n",
    "train_images = []\n",
    "for camera in cameras:\n",
    "    for fname in sorted(os.listdir(train_path + '/' + camera)):\n",
    "        train_images.append((camera, fname))\n",
    "\n",
    "train = pd.DataFrame(train_images, columns=['camera', 'fname'])\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2640, 1)\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "for fname in sorted(os.listdir(test_path)):\n",
    "    test_images.append(fname)\n",
    "\n",
    "test = pd.DataFrame(test_images, columns=['fname'])\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_center_crop(img, d=250):\n",
    "    cy = img.shape[0] // 2\n",
    "    cx = img.shape[1] // 2\n",
    "    return img[cy - d:cy + d, cx - d:cx + d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>Sony-NEX-7</td>\n",
       "      <td>(Nex7)133.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549</th>\n",
       "      <td>Sony-NEX-7</td>\n",
       "      <td>(Nex7)256.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>HTC-1-M7</td>\n",
       "      <td>(HTC-1-M7)88.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Motorola-X</td>\n",
       "      <td>(MotoX)108.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Samsung-Galaxy-Note3</td>\n",
       "      <td>(GalaxyN3)166.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    camera              fname\n",
       "1413            Sony-NEX-7      (Nex7)133.JPG\n",
       "1549            Sony-NEX-7      (Nex7)256.JPG\n",
       "2737              HTC-1-M7   (HTC-1-M7)88.jpg\n",
       "1935            Motorola-X     (MotoX)108.jpg\n",
       "1174  Samsung-Galaxy-Note3  (GalaxyN3)166.jpg"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 5\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True)\n",
    "\n",
    "# Get some training data for PCA\n",
    "random_images = train.sample(100)\n",
    "random_images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 750000)\n",
      "[(750000,), (750000,), (750000,), (750000,), (750000,), (750000,), (750000,), (750000,), (750000,), (750000,)]\n"
     ]
    }
   ],
   "source": [
    "img_set_reds = []\n",
    "for i, r in random_images.iterrows():\n",
    "    # If you uncomment last part, you can extract features only over a certain channel\n",
    "    x = get_center_crop(cv2.imread(train_path + '/' + train['camera'][i] + '/' + train['fname'][i]))#[:,:,0] \n",
    "    img_set_reds.append(np.ravel(x)) # PCA takes instances as flatten vectors, not 2-d array\n",
    "\n",
    "img_set_reds = np.asarray(img_set_reds)\n",
    "print(img_set_reds.shape)\n",
    "print([img_set_reds[i].shape for i in range(10)])\n",
    "pf = pca.fit(np.asarray(img_set_reds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pca_features(img):\n",
    "    img = np.ravel(img).reshape(1, -1)\n",
    "    return pf.transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.40041442,  0.93382796,  0.49127537,  2.45095983, -3.75219319])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = get_pca_features(get_center_crop(\n",
    "        cv2.imread(train_path + '/' + r['camera'] + '/' + r['fname'])))\n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_stats(q, iolock):\n",
    "    while True:\n",
    "        img_path = q.get()\n",
    "        if img_path is None:\n",
    "            break\n",
    "        \n",
    "        if type(img_path) is tuple:\n",
    "            img = cv2.imread(train_path + '/' + img_path[0] + '/' + img_path[1])\n",
    "            key = img_path[1]\n",
    "        else:\n",
    "            img = cv2.imread(test_path + '/' + img_path)\n",
    "            key = img_path         \n",
    "        \n",
    "        # Some images read return info in a 2nd dim. We only want the first dim.\n",
    "        if img.shape == (2,):\n",
    "            img = img[0]\n",
    "        \n",
    "        # crop to center as in test    \n",
    "        img = get_center_crop(img)\n",
    "        pca_feats = get_pca_features(img)\n",
    "        color_info[key] = (pca_feats[0][0],pca_feats[0][1],\n",
    "                           pca_feats[0][2],pca_feats[0][3],pca_feats[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['pca0','pca1', 'pca2','pca3','pca4']\n",
    "\n",
    "for col in cols:\n",
    "    train[col] = None\n",
    "    test[col] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCORE = 8\n",
    "\n",
    "color_info = mp.Manager().dict()\n",
    "\n",
    "# Using a queue since the image read is a bottleneck\n",
    "q = mp.Queue(maxsize=NCORE)\n",
    "iolock = mp.Lock()\n",
    "pool = mp.Pool(NCORE, initializer=color_stats, initargs=(q, iolock))\n",
    "\n",
    "for i in train_images:\n",
    "    q.put(i)  # blocks until q below its max size\n",
    "\n",
    "for i in test_images:\n",
    "    q.put(i)  # blocks until q below its max size\n",
    "    \n",
    "# tell workers we're done\n",
    "for _ in range(NCORE):  \n",
    "    q.put(None)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "color_info = dict(color_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n, col in enumerate(cols):\n",
    "    train[col] = train['fname'].apply(lambda x: color_info[x][n])\n",
    "    test[col] = test['fname'].apply(lambda x: color_info[x][n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['camera'].values\n",
    "X_train = train[cols].values\n",
    "X_test = test[cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=12, n_jobs=1,\n",
       "            oob_score=False, random_state=777, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=12, max_depth=5, random_state=777)\n",
    "clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca0', 'pca1', 'pca2', 'pca3', 'pca4']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "subm = pd.read_csv(data_path + '/' + 'sample_submission.csv', index_col='fname')\n",
    "subm['camera'] = y_pred\n",
    "subm.to_csv('pca_benchmark.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
